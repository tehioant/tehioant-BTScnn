%Breast masses and clustered microcalcifications are the main signs of early breast cancer (Sec.~\ref{sec:BreastCancer}). 
Traditional CAD systems for breast cancer are composed of succesive stages: preprocessing and image enhancement, localization of suspicious regions, feature extraction from suspect image patches, feature selection and region classification using machine learning.
Tang et al.~\cite{Tang2009} review the state-of-the-art in CAD systems. We focus on convolutional networks applied to lesion detection and diagnosis in mammographic images.

%There are mainly two groups who have worked on convolutional network aapplied to breast cancer: one from the Department of Radiology of the University of Michigan and one from the Department of Radiology of Georgetown University.
\paragraph{Overview}
In 1995, Sahiner et al.~\cite{Sahiner1996} used simple convolutional networks to detect masses.
%Although results were competitive, the research community favored feature-based classifiers, such as regular neural networks, that [employ|exploit|work with|use] expert knowledge and advanced image techniques.
Although results were competitive, the research community favored feature-based classifiers, such as regular neural networks, that employed expert knowledge and advanced image techniques.
During that time, Lo et al.~\cite{Lo1995, Lo1998} used convolutional networks to detect individual microcalcifications.
This work was continued by Gurcan et al.~\cite{Gurcan2002} who selected an optimal architecture to detect individual microcalcifications. The optimized network played a small role in two CADe systems for clustered microcalcifications: one for film mammography~\cite{Gurcan2002} and one for digital mammography~\cite{Ge2006}.
%Both systems have a similar layout consisting of preprocessing, image enhancement, segmentation of potential microcalcifications, false positive reduction, regional clustering and false positive reduction of clusters.
Until this point, researchers used few data to train networks (2 to 3 layers, less than 10 thousand parameters) without modern features to classify preselected regions.
Recently, Arevalo et al.~\cite{Arevalo2016} diagnosed breast masses with a bigger convolutional network (4 layers, 3.4 million parameters) that incorporates many deep learning advances; it outperformed hand-crafted and image-based features.
Lastly, Dubrovina et al.~\cite{Dubrovina2015} trained a convolutional network to perform segmentation of different breast tissues; despite the small network and data set, results were promising.
To the best of the author knowledge, this is the only attempt to use supervised convolutional networks for mammographic segmentation~\footnote{Petersen et al.~\cite{Petersen2014} segmented breast tissue using a convolutional autoencoder.}.
These last studies are the most relevant to this thesis.

In summary, convolutional networks have been used sporadically for breast cancer detection and diagnosis but they have not been used for lesion segmentation or trained with big data sets of digital mammograms. 
%We apply insights from these works to train end-to-end all convolutional networks for lesion segmentation in digital mammograms.
%It is worth noting that this is a significantly harder task than simple classification where images are already sorted or than tissue segmentation, when pixels can be easily discriminated by intensity values or other measures appearances between regions are quite disimilar which is not the case with lesions.. Lesion segmentation has more confounding variables. Plus, we try to make use of preprocessing and postprocessing techniques to obtain better results.

The following sections expand on the work mentioned above. Architectural details are compiled in Table~\ref{tab:BrCaConvNetArchitectures}% compiles the architectural details.

%If put up here, delete the references to the table below

\begin{comment}
Separated in blocks:
	1. Initial mass: Sahiran 1996 (michigan)
	2. Intial microcalc detection: Lo 1995- Lo 1998 (georgetown/both)
	3. Optimal architecture for microcalc: Gurcan 2000-Gurcan 2002 (michigan)
	4. CAD for microcalcification in FFDM. Ge 2007 (CAD for masses didn't use Convnets, used LDA and rule-based classifiers). (michigan)
	5. Late mass diagnosis
\end{comment}

\subsection{Detection of breast masses}
%******************************** Wei1995 *******************************************
% Wei, Datong, Sahiner, Berkman, Chan, Heang-Ping, Petrick, Nicholas. Detection of masses on mammograms using a convolution neural network (1995) ICASSP, IEEE International Conference on Acoustics, Speech and Signal Processing - Proceedings, 5, pp. 3483-3486.
% Pretty much the same as Sahiner1996 but smaller and simpler.
The first attempt to use convolutional networks for breast cancer is reported in "Detection of masses on mammograms using a convolution neural network"~\cite{Wei1995}. This four-page article was expanded in~\cite{Sahiner1996}.

%******************************** Sahiner1996 **************************************
% Sahiner, B., Chan, H.-P., Petrick, N., Wei, D., Helvie, M.A., Adler, D.D., Goodsitt, M.M. Classification of mass and normal breast tissue: A convolution neural network classifier with spatial domain and texture images (1996) IEEE Transactions on Medical Imaging, 15 (5), pp. 598-610. 
\begin{comment}
- detection of tumors
- uses mass to mean benign or malign tumors (growths of cell with no purpose) and normal tissue is other masses (cysts, liquids, no mass at all, etc)
- 168 mammograms: 168 positive classes, 504 negative classes
- 0.87 AUC, 0.9 sensitivity, 0.69 specificity
- texture "contains useful information that can be used to effectively distinguish masses from normal tissue." Not sure 'bout this
- one output sigmoid
- GD+momentum, adaptive learning rates,  early stopping
- manually extracted ROI's
- "The average size (length of the long axis) of the masses, as estimated by the radiologists, was 12.2 mm., and the standard deviation of the mass size was 4.5
mm." i could use a 2-2.5 cm filter.
- digitized mammograms (not digital)
- For each mamogram, 4 ROIs extracted (a tumor, fatty tissue, dense tissue nad mixed dense/fatty tissue)
- each pixel 0.1 mm
- 256 pixels by 256 pixels initial image (2.56 cm by 2.56 cm)
- background reduction (averaging a 2 by 2 box with an average of 4 cardianl boxes). 
- (Because they didn't have the power) nonoverlapping average pooling (where the avg function is applied instead of the max function) with 16 x 16 filters (rsulting in 16 by 16 image patches) and 8 by 8 filters (resulting in 32 by 32 image patches)
- 8 rotations(0,90,180,270 and flipped). Used all to calculate a single output for training, so all 8 will contribute a single number. Output obtained as average among all of them.
 
- Experiment with single input image:
	single hidden layer network with variable feature maps and kernel size.
	Best results with kernel size 10 for 16 and 20 for 32.
	small grid search(needed to test more values).
	0.83 AUC
- GLDS texture features: contrast, angular second moment, enlropy and mean. Calculated at different subregions of the original 256 by 256 pixel image (it produces a 16 by 16 image).
- Experiment with GLDS plus pool-averaged image: 
	one hidden layer (3 feature maps, 10by 10 filter)
	16 by 16 raw input and one of the four possible GLDS
	good results already 0.86s 0.85
SGLD features: correlation, entropy, and difference entropy 
- Experiment with SGLD plus pool-averaged input:
	one hidden layer (3 feature maps, 10 by 10 filter)
	16 by 16 plus one
	NOt so good 0.84 AUC
- Good one: one of each plus index 
	one hidden layer
	varying kernel size and number of feature maps
	3 input images: pool-averaged, mean GLDS, SGLD correlation
- why not try imputing all possible GLDS+ all SLDS features+ raw  (8 feature maps) or deeper network? Probably because of no comp power
- give more info helps the AUC, maybe the improvement comes from the info lost by subsampling and the shallowness of the network, a deeper network with million parameters (and bigger input) will be able to learn the GLDS or SLDS features.
- texture images improve classification
- conv architecture not as important as texture images. (more image data/info)
- also points the need for bigger networks and the suboptimality of the hyperparamteer search (not all reasonable combination tried)
- no difference on 16 \times 16 vs 32 \times 32 (not sure about these because they were not one tested on the exact same architecture).
\end{comment}
They used a small convolutional network (2 layers, $\sim$1K parameters) to detect masses.
%~\footnote{They use the term mass to refer to tumors (cancerous or non-cancerous) but not to other kind of breast masses such as cysts and fibroadenomas.}.
The data set consisted of 672 manually selected potential masses from 168 digitized mammograms: out of which 168 were positive examples and 504 were dense or fatty tissue. Background reduction was performed using a rather convoluted method. The original images $256 \times 256$ (equivalent to $2.56 \times 2.56$ cm) were downsampled via non-overlapping average pooling to size $16\times 16$; downsampling to $32 \times 32$ pixels was also tried and produced similar results. Data was augmented by using 4 rotations (0°, 90°, 180° and 270°) on each original image and on each horizontally flipped image (8 in total per each training image).
%~\footnote{The original article does not mention data augmentation but it was probably performed given that they obtained the same results.}. 
The network was trained via batch gradient descent plus momentum and per parameter adaptive learning rate. Two sets of experiments were performed: first, the $16 \times 16$ image patches (and their 8 rotations) were used for training producing 0.83 AUC on the best architecture; later, these image patches were complemented with 2 $16 \times 16$ ``texture-images'' calculated from the initial image (a $16\times 16 \times 3$ input volume) producing 0.87 AUC, 0.9 sensitivity and 0.69 specificity with the best network architecture.
Authors showed that network architecture was not as important for performance as providing the network with texture information.
% Authors showed that texture information improved performance regardless of the architecture.
Texture features give back some of the information lost during downsampling, which explains the improvement. Authors also acknowledge that the network architecture is far from optimal given its simplicity (one convolutional layer with three filters) and the incomplete hyperparameter search. A deeper network with bigger input size could produce better results without the need for handcrafted texture features.
%Learned lesson: masses from 0.7-1.7 cm^2, conv arch may not be as important, bigger networks are better. More masses there is, less change of cancer. Cancer tumors are denser, > 0.8 mm, irregular shape and poorly defined margins




\subsection{Detection of microcalcifications}
%*************************************** Lo1995 *************************************
% Lo, S.-C.B., Chan, H.-P., Lin, J.-S., Li, H., Freedman, M.T., Mun, S.K. Artificial convolution neural network for medical image pattern recognition (1995) Neural Networks, 8 (7-8), pp. 1201-1214
\begin{comment}
- detect microcalcifications
- only years after lecun showed it to be good on the mnist dataset.
- preselected images
- Background removal with wavelet high pass filtering ("a three-level wavelet transform was used and only the lowest frequency was eliminated for high-pass filtering before image reconstruction."). For lung nodules: Background removal like constrast enhancement.
- YES/NO output. For lung nodules: degrees of sensitivity in output(1-10) instead of disease/no disease . 
- Rotation and translation invariance. 0,90,180,270 and flipped over. (all of this on the small 32 by 32 images). No use of translation, it talks about it, though.
- Uses ROC/AUC.
- Each pixel represented 0.105 mm. (for instance 16 pixel input was 1.7mm)
- Same set used for validation and test
- using the data augmented versions one after the other in training gives better performance here (not sure why)
- 30-fold crossvalidation results reported (no test set): 0.89 AUC for individual miscrocalcifications and 0.97 for clustered microcalcif. 
- not quite clear if label were beningn/malign, microcalc/non-microcalc. It hink it is detection not diagonsis
- not clear how they measure the detection of microcalc. I think, of those microcalc detected from the normal algorithm if more than 3 were in the same 1 cm^2 area, it was considered as if the convnet detcted a cluster. 
- Easier to detect clusters these way because there could be 20 micorcalcif in a 1 cm^2 area and it only needs to detect 3.
- Bunch of questions on how on hell is this done. It could be done in a way that would help a lot the results, maybe that is why they have 0.97 AUC
\end{comment}
The first use of convolutional networks to detect microcalcifications is reported in~\cite{Lo1995}. They performed various experiments on a small convolutional network (3 layers, $\sim$5.4K parameters). The input size ($16\times 16$), number of convolutional layers ($2$) and kernel size ($5\times5$) were chosen using a validation set, although few options were explored: input sizes of 8, 16 and 32; one and two hidden layers and kernel sizes of 2, 3, 5 and 13.
A high sensitivity image technique was used to obtain a set of 2104 image patches ($16 \times 16$ pixels equivalent to $0.17 \times 0.17$ cm) of potential microcalcifications from 68 digitized mammograms; of these, 265 were microcalcifications and 1821 were ``false subtle microcalcifications". Prior to training, a wavelet high-pass filter was used to remove the background. Each image was flipped horizontally and 4 rotations for each the original and flipped image were used for training (0°, 90°, 180° and 270°).
The network reached 0.89 AUC when identifying individual microcalcifications and 0.97 AUC for clustered microcalcifications---results obtained with a 30-fold cross validation. More than two individual microcalcifications detected on a 1 $cm^2$ area is considered a cluster detection, the predicted probability for the cluster is the average of the probabilities of all suspect patches inside the 1 $cm^2$ area~\footnote{This evaluation is not clearly explained in the article or in~\cite{Lo1998} so our interpretation may be incorrect. This affects the validity of the reported results.} Other performance metrics were not explicitly reported.
% Do I only consider the patches who were suspect in the first place and are inside the 1 cm2?. What if a single suspect patch has more than 2 microcalcifications, is that considered a cluster detection?, how do I make the cluster grouping. How is the labelling in the original images done, are the 1 cm^2 preset, when is a cluster not detected. Are only the dected clusters used to calculate the rsulting NDDI?
% Is this left intentionally vague?
This article showed that deeper networks, background removal and data augmentation improved results. Together with~\cite{Sahiner1996}, it proved that simple convolutional networks can be used to detect breast cancer lesions.
% Lesson learned: two hidden layer newtwork produces better results, background reduction is neccesary and using matrices invariance to augment the data helps.
% 1 cm2 for clustered microcalcifications

% ********************************* Lo1995 *****************************************
% Shih-Chung B. Lo ; Huai Li ; Jyh-Shyan Lin ; Akira Hasegawa ; Chris Y. Wu, et al. "Artificial convolution neural network with wavelet kernels for disease pattern recognition", Proc. SPIE 2434, Medical Imaging 1995: Image Processing, 579 (May 12, 1995); 
% Detection of microcalcifications
% "Wavelet based kernels". Same results.

%********************************** Chan1995 ****************************************
% Chan, H.-P., Lo, S.-C.B., Sahiner, B., Kwok Leung Lam, Helvie, M.A. Computer-aided detection of mammographic microcalcifications: Pattern recognition with an artificial neural network (1995) Medical Physics, 22 (10), pp. 1555-1567.
% Initial set divided in obvious, average and subtle microcalcifications
% Trained with hard cases and proved different architectures resulting in AUC 0.9

%********************************* Lo1996 *******************************************
%Lo, S.-C.B., Li, H., Lin, J.-S., Hasegawa, A., Tsujii, O., Freedman, M.T., Mun, S.K. Detection of clustered microcalcifications using fuzzy modeling and convolution neural network (1996) Proceedings of SPIE - The International Society for Optical Engineering, 2710, pp. 8-15.
% A fuzzy classification modeling was employed to extract each suspected microcalcification
% Fuzzy function also used to determine the of spots near a cluster as part of the cluster (it received as input the distance to the cluster an the output of the convolutional network)
% Sensitivity 90% at 0.5 FP per image 

%************************************* Lo1998 ***************************************
% Lo, S.-C.B., Lin, J.-S.J., Freedman, M.T., Mun, S.K. Application of Artificial Neural Networks to Medical Image Pattern Recognition: Detection of Clustered Microcalcifications on Mammograms and Lung Cancer on Chest Radiographs (1998) Journal of VLSI Signal Processing Systems for Signal, Image, and Video Technology, 18 (3), pp. 263-274.
\begin{comment}
- similar to Lo 1995:
	detect microcalcifications
	pre-selected image patches
	8 rotations per image(0,90,180,270 and flipped)
	sigmoid activation function
	16 by 16 pixel size
	5 by 5 filters
	2 outputs
	clustering method
- only 10 groups per layer
- "Typically, the sizes of microcalcifications vary from 0.16 mm to 1.0 mm."
- each pixel 0.1mm, more than that may make dissapear the microcalc.
- DYSTAL network, regular neural network, and convolutional network. convnet ouptperforms them.
- rotation and translation invariance.
- gaussian-like activation function in input (?)
- 38 "digital" mammograms: 220 true and 1132 subtle microcalcififcations
- divided into two roughly equal sets for test (no cross validation)
- 0.9 AUC for microcalc and 0.97 AUC for clustered microcalcif
\end{comment}
A convolutional network with a similar architecture (3 layers, $\sim$4.5K parameters) was presented by the same group in~\cite{Lo1998}. It detects microcalcifications from $16 \times 16$ image patches that were pre-selected and preprocessed using the same techniques. For these experiments, nonetheless, they used 38 digitized mammograms and extracted 220 microcalcifications and 1132 negative examples that were randomly divided into a training and test set of roughly equal sizes. The network obtained a 0.9 AUC for individual microcalcifications and 0.97 AUC for clustered microcalcifications (also evaluated as in~\cite{Lo1995}). It showed that a convolutional network outperforms a regular neural network and a DYSTAL network in  detecting clustered microcalcifications when using raw pixels as input features.
% Lesson learned: better data is good, microcalcifications are 0.2-1 mm




%********************************* Gurcan2000 *************************************
% Gurcan, M.N., Sahiner, B., Chan, H.-P., Hadjiiski, L., Petrick, N. Optimal selection of neural network architecture for CAD using simulated annealing (2000) Annual International Conference of the IEEE Engineering in Medicine and Biology - Proceedings, 4, pp. 3052-3055. 
% Optimal network architecture with simulated annealing (3 pages). Simple

%********************************* Gurcan2001 *************************************
% Gurcan, M.N., Sahiner, B., Chan, H.-P., Hadjiiski, L., Petrick, N. Selection of an optimal neural network architecture for computer-aided detection of microcalcifications - Comparison of automated optimization techniques (2001) Medical Physics, 28 (9), pp. 1937-1948.
% Comparaison of automatic hyperparamter search methods.
% Hyperparameters are 4: number of feature maps in the two layers, kernel sizes in two layers.
% Steepest Descent SD, Simulated Annealing SA and Genetic Algorithms GA
% It compares efficiency of algorithms but not architectures. 
% Simulated annealing beat all.

%********************************* Gurcan2002a **************************************
% Gurcan, M.N., Chan, H.-P., Sahiner, B., Hadjiiskii, L.M., Petrick, N., Helvie, M.A. Optimal neural network architecture selection: Effects on computer-aided detection of mammographic microcalcifications (2002) Proceedings of SPIE - The International Society for Optical Engineering, 4684 III, pp. 1325-1330. 
% Pretty much the same as Gurcan2002b.

%******************************* Gurcan2002b ****************************************
% Gurcan, M.N., Chan, H.-P., Sahiner, B., Hadjiiski, L., Petrick, N., Helvie, M.A. Optimal neural network architecture selection: Improvement in computerized detection of microcalcifications (2002) Academic Radiology, 9 (4), pp. 420-429.
\begin{comment}
- detect microcalcificication
- compares the optimized version with a manually selected one.
- 108 digitized mamograms for training, 152 for validation and 472 for test(253 malignant) (pixel size 0.1mm)
- Each region is preprocessed to retain the breast, each possible microcalcification is segmented and then they are classified. Classification: rule based classifier, then the convnet and then each microcalcification is regionally clustered
- optimizes number of feature mpas per layer and filter sizes
- used simulated annealing, a genentic algorithm and hillclimbing, with the AUC as the objective function.
- some of the false positives detected were deleted. dataset balanced
- from 77.2 % to 84.6% at FP rate 0.7
-"The optima! architecture (N1-N2-K1-K2) was determined to be 14-4-5-5 when the architecture was trained with group ! and tested with group 2 and 14-10-5-7 when the training and thetest sets were switched."
- accuracy can be improved by seleecting a good architecture (it clashes with wath people teaches now).
- using bad scanners results in lower performance.
- 14 and 10 feature maps seem to be the max possible feature maps (from Gurcan2000). result is not valid then. WOuldn't be useful anyway
- Don't say the total number of preselected ROIs in the test set
- Don't say how each method works or what ranges each looks for, or how did the selected architectures compare to the not selected ones.
- Don't say exactly what method was used GA, simulated annealing(i think this one!) or hill-climbing.
\end{comment}
Gurcan et al.~\cite{Gurcan2002} optimized the filter size and number of filters of each convolutional layer of a network used to detect clustered microcalcifications (3 layers, $\sim$7.6K parameters). The convolutional network was part of a CAD system that identifies and enhances the breast area via a bandpass filter, segments potential microcalcifications with adaptive thresholding methods, filters the suspect areas with a rule-based classifier, classifies the remaining image patches with a convolutional network and clusters individual microcalcifications to obtain the detected clustered microcalcifications. The network was trained on 1117 image patches ($16 \times 16$ pixels equivalent to $0.16 \times 0.16$ cm) obtained from 108 digitized mammograms without data augmentation. The best architecture had 14 feature maps on the first convolutional layer with filter size $5\times 5$ and 10 on the second layer with a $7 \times 7$ filter. Details about the hyperparameter search or network training are not provided. The CAD reached 84.6\% sensitivity at 0.7 false cluster detections per image. 
%Other performance metrics were not provided. %~\footnote{These are results for the entire CAD on 472 mammograms with 253 microcalcifications. They do not explicitly state how many potential microcalcifications arrived at the convolutional network stage or what was its performance on them}.
The article shows that optimizing the network architecture improves CAD performance significantly; nonetheless, given the small training set and incomplete hyperparameter search results may vary. 
% Better scanner improves accuracy. good architecture may be important




%*********************************** Ge2005 *****************************************
%Ge, J., Wei, J., Hadjiiski, L.M., Sahiner, B., Chan, H.-P., Helvie, M.A., Zhou, C. Computer-aided detection of microcalcification clusters on full-field digital mammograms: Multiscale pyramid enhancement and false positive reduction using an artificial neural network (2005) Progress in Biomedical Optics and Imaging - Proceedings of SPIE, 5747 (II), art. no. 83, pp. 806-812.
% Detect microcalcifications in digital (!) mammograms
% "we investigated the performance of a nonlinear multiscale Laplacian pyramid enhancement method in comparison with a box-rim filter at the image enhancement stage"
% 0.97 AUC

%********************************* Ge2006 *****************************************
% Ge, J., Sahiner, B., Hadjiiski, L.M., Chan, H.-P., Wei, J., Helvie, M.A., Zhou, C. Computer aided detection of clusters of microcalcifications on full field digital mammograms (2006) Medical Physics, 33 (8), pp. 2975-2988.
\begin{comment}
- Like Gurcan2002 but slightly changed for digital mammography
- six stages
- trained on manually sleected miucrocalcifications and some selected by the CAD which were not  microcalcifications
- threshold chosen by training as 0.4 to remove signals with low CNN scores
\end{comment}
%\cite{Ge2006} tailored this system to digital mammograms.
Ge et al.~\cite{Ge2006} tailored the CAD system developed in~\cite{Gurcan2002} to digital mammograms.
It consists of seven stages: preprocessing via inverted logarithmic transformation, image enhancement via box-rim filter, segmentation of potential microcalcifications via thresholding, classification of individual candidates via rule-based classifier and convolutional network, regional clustering via neighborhood growing, stepwise LDA feature selection and classification via LDA. The convolutional network had the same optimized architecture and was trained on around 500 $16 \times 16$ image patches obtained from 48 digital mammograms: half of which were microcalcifications. Its threshold was manually set to 0.4. The network reached 0.96 AUC for the detection of individual microcalcification. 

%********************************* Ge2007 ******************************************
% Ge, J., Hadjiiski, L.M., Sahiner, B., Wei, J., Helvie, M.A., Zhou, C., Chan, H.-P. Computer-aided detection system for clustered microcalcifications: Comparison of performance on full-field digital mammograms and digitized screen-film mammograms (2007) Physics in Medicine and Biology, 52 (4), art. no. 008, pp. 981-1000.
% better for FFDM than SDM. 
% 0.96 AUC
% in masses, it is similar for both.
%Ge et al.~\cite{Ge2007} compared the previous CAD systems.
These CAD systems were compared in~\cite{Ge2007}: digital mammograms considerably improved performance. This seems intuitive given that digital mammograms have less noise which allows the system to pick up subtler details without the need for manual enhancement.


\subsection{Diagnosis of breast masses}
%******************************* Jamieson2012 *************************************
% A. R. Jamieson, K. Drukker, and M. L. Giger, “Breast image feature learning with adaptive deconvolutional networks,” 2012.
\begin{comment}
- Unsupervised convolutional networks, trained as autoencoders with some slight variations. Uses SVM for classification.
- Not really a convnet
\end{comment}

%********************************* Agarwal2015 **************************************
\begin{comment}
- not published report
- DDSM database (8752 mammograms)
- only lesion treatment
- they do ~detection (masses vs calcifications) and diagnosis (benign vs malignant).
- two convnest fpr eachtask
- lesions were segmented from the images using the truth labels. 
- Each image is selected so that the shorter dimension is 64 (the other dimension will normally be larger), then 2 to 3 patches are sampled at random positions and each one is rotated 8 times.
- resulted in 50K lesion images
- negative and benign = benign, everything else= malignant
- tried different network sizes.
- accuracy 87% for micro vs mass and 69.8% for malignancy.
\end{comment}
\begin{comment}
A recent unpublished report~\cite{Agarwal2015} uses a big convolutional network (8 layers, $\sim$3.6M parameters) with recent features to diagnose lesions as benign or malignant. Clustered microcalcifications and masses are segmented from 8752 mammograms obtained from a public database (DDSM). Two to three square images ($64 \times 64$) are randomly sampled from each lesion and each of these is rotated 8 times (at 45° steps) producing 50K image lesions in total. No further preprocessing is performed. The convolutional network obtains 69.8\% accuracy on the task. Other performance metrics are not provided. This is a project report for a course in Convolutional Networks~\cite{Karpathy2015} and may be incomplete or incorrect. We acknowledge it here for completeness.
\end{comment}

%***************************** Arevalo2015 ****************************************
\begin{comment}
- Colombia and Porto
- Benign vs. malign lesions
- Each lesion was cropped to 150x150 pixel images---bigger lesions wer reduced preserving aspect ratio.
- 8 transformations: rotations at 0, 90, 180, 270 and same rotations for flipping
- Enhancement: global contrast normalization (substract the meean of all intensities from each pixel) and local contrast normalization (each pixel is substracted the mean of a local neighborhood (11x11) and divided by the standard deviation of the neighborhood)
- They train a linear SVM with the features from the first fully connected layer of the network to perfrom the final classification.
- 1.7M paramteres(although they say they have 4.6M)
- film mammograms, not digital.
- dropout and max-norm
- early stopping
- 25 different architectures tried, and C in SVM cost also tuned
- Cons: Uses big filters and big pooling filters too because the input size (150x150) makes it unmanageable otherwise, resizes the images, uses only two convolutions (each followed by pool) plus a couple of softmaxs.
- Doesn't talk about momentum hyperparameters or learning.
- use an nvidia tesla k40(2880 cores!)
- adding more layers to the network (it is the fully convolutionla layer) improves performance
- AUC 0.86
- Maxout uses two transformations. Odd way to do maxout, i would rather use the entre 800 outputs
- bias for each unit in feature maps (3 million biases) (i can beat em)
- They compared again HOG, HGD and other 17 hand-crafted features. The network beat them all.
- Using a nonlinear classifier with other features may have produced better results.
\end{comment}

%******************************* Arevalo2016 **************************************
% John Arevalo, Fabio A. González, Raúl Ramos-Pollán, Jose L. Oliveira, Miguel Angel Guevara Lopez, Representation learning for mammography mass lesion classification with convolutional neural networks, Computer Methods and Programs in Biomedicine, Available online 7 January 2016, ISSN 0169-2607, http://dx.doi.org/10.1016/j.cmpb.2015.12.014.
\begin{comment}
- 50% training, 10% validation, 40% test.
- Probable to overfit to the validation set.
- they select a model using the validation set and then join eveyrhting otgether an dmake a different division for 5 runs. This is not  a good practice, examples used to choose hyperparamteres and architecture will also appear in the new test sets so results will be better.
- combination of both 17 hand-crafted features plus convnet features (before Linear SVM) did not produce significant improvements.
\end{comment}
Arevalo et al.~\cite{Arevalo2016} trained a convolutional network (4 layers, $\sim$3.4M parameters~\footnote{They actually learned 4.6 million parameters but many were redundant.}) with modern deep learning techniques to diagnose masses. The data set contained 426 benign and 310 malignant masses obtained from 736 digitized mammograms. Lesions were cropped tightly, resized to $150\times150$ pixels and augmented (original and flipped images were rotated at 0°, 90°, 180° and 360°). 
Pixels were normalized globally---subtracting the mean intensity of the $150\times150$ patch---and locally---subtracting the mean intensity of an $11\times11$ neighborhood and dividing by its standard deviation.
The final architecture was chosen among 25 architectures using a validation set.
%; they use $5\times5$ and $7\times7$ convolutional filters, which are slightly bigger than recommended.
The network extracts image features and forwards them to a separate linear classifier for scoring.
This setup competed against linear classifiers trained on HOG features, HGD features, hand-crafted features and features from a convolutional network trained on natural images. The convolutional network trained on mammographic images achieved the best result: 0.86 AUC~\footnote{This may be optimistic due to flawed experiment design: examples used to choose the model could belong to the test set.}.
Moreover, adding hand-crafted to network-produced features proved ineffective.
%Convolutional networks try to generate linearly separable features, this gives them an advantage that could dissapear if non-linear classifiers were used.
This work showed that convolutional networks outperform image-based and hand-crafted features in breast cancer diagnosis. They also learned that normalization and additional convolutional layers facilitate learning.
%Lesson learned: it can be used for diagnosis, better than hand-crafted, normalization is necessary, deeper netwroks are better, data is needed, combining features may be good

\subsection{Tissue segmentation}
%*************************** Petersen2014 *****************************************
% K. Petersen, M. Nielsen, P. Diao, N. Karssemeijer, and M. Lillholm, “Breast Tissue Segmentation and Mammographic Risk Scoring Using Deep Learning” in Breast Imaging (H. Fujita, T. Hara, and C. Muramatsu, eds.), vol. 8539 of Lecture Notes in Computer Science, pp. 88–94, Springer International Publishing, 2014.
\begin{comment}
- convolutional sparse autoencoder (unsupervised)
- does segmentation(background, pectoral muscle and breast tissue), density classification (fatty and dense) and risk scoring/diagnosis (healthy and disease).
- 990 film mammograms: 250 controls and 245 future-cancers, i.e., mammograms were obtained 2-4 years before cancer was actually detected in the patient.
- semisupervised: convolutional networks are trained as a deep sparse autoencoder. Later full classification with on the obtained features.
- 50K patches () randomly selected
- obtained better results with convolutional layer instead of pooling
- Many convolutional networks are trained with segments of different scales and all results from different networks is used in the FC layers
- not clear whether they do segmentation or scoring for healthy and diseased. It looks like it is scoring.
- 0.65 AUC
- looks a bit more like transfer learning, the network learns general features form mammograms, and then a fine-tuned classifier is trained on top of it.
\end{comment}
%Peterson2014 trained a convolutional network with unlabelled data to perform breast segmentation, i.e., separate between background, pectoral muscle and breast tissue. the network was trained in xxx digitized mammograms with xxx.. A classifier was trained on top of this network to predict the pixel scores. Details of the architecture are not provided. It does, though get to XX% IOU, digitized mammograms.

%************************************** Dubrovina2015 ****************************
%A. Dubrovina, P. Kiselev, B. Ginsburg, S. Hashoul and R. Kimmel Proc. Deep Learning in Medical Image analisys (DLMIA), MICCAI workshop, 2015
\begin{comment}
- trained with patches, tested with fully convnet
- Tissue segmentation (not lesion segmentation): pectoral muscle, fibroglandular tissue, nipple, and general breast tissue and background.
- data set 40(!) digital(!) mammograms
- no enhancement
- convnet produces 4-d score vectors (for each class)
- small 61x61 input images
- global zero-mean (substract the mean of all intensity values) (not so necessary). 
- cross-entropy loss
- by overlapping, they get 8x10^5 training patches
- overlapping pooling
- they do not use zero-padding,
- 829 x 640 original image dimensions
- train on 39 images, test on 1 LOOCV
- shift-and-stitch method (no upsampling)
- post-processing: regions are filled, and clusters less than a threshold are deleted (threshold is set arbitrarily)
- SGD with momentum
- mini-batches of 256 image patches, learning rate = 0.001, learning rate was reduced by a factor of 10 after 10 and 20 epochs, momentum 0.9, weight decay 0.0005
Dropout removed during testing.
- changing from patch normalization to global normalization had minor effects (on classfication, not in learning, learning was done with normalized patches).
\end{comment}
% A [supervised] convolutions network was usd in~\cit....
A convolutional network was used in~\cite{Dubrovina2015} to segment breast tissue into four categories: pectoral muscle, fibroglandular tissue, nipple and general breast tissue. A network was trained on approximately 800\,000 overlapping patches ($61\times61$ pixels) cropped from 39 digital mammograms and tested on a single mammogram; this was repeated for every image and results were averaged. Pixels were zero-centered but not further enhanced. The network architecture (6 layers, ~34K parameters) was chosen by hand; the network is deep although simple. It was trained using stochastic gradient descent with momentum, learning rate decay, weight decay, dropout and mini-batches of 256 patches. Its output was preprocessed by filling regions and deleting clusters smaller than a predefined threshold.
%Instead of upsampling predictions, they applied the network at different positions and interlaced the outputs to produce the desired size.
This network reached 0.55 mean IOU. They proved that convolutional networks can perform mammographic image segmentation even with little labelled data. Bigger networks trained with more examples could improve results.
%Lesson learned: I can use little data, I cna do segementation

\begin{landscape}
\centering
\begin{longtable}{cp{3.4cm}p{7cm}p{2.7cm}p{1.3cm}c}
	\caption[Breast cancer convolutional network architectures]{Architectures of the convolutional networks used for breast cancer detection and diagnosis.}\label{tab:BrCaConvNetArchitectures}\\
	\hline
	\textbf{Article}&\textbf{Goal}&\textbf{Architecture}&\textbf{Volumes} & \textbf{Filters} & \textbf{\# Params}\\
	\hline
	\endfirsthead
	\caption*{Table~\ref*{tab:BrCaConvNetArchitectures} (continued): Architectures of the different convolutional networks used for breast cancer detection and diagnosis.}\\
	\hline
	\textbf{Article}&\textbf{Goal}&\textbf{Architecture}&\textbf{Volumes} & \textbf{Filters} & \textbf{\# Params}\\
	\hline
	\endhead
	\hline
	\endfoot
	\hline
	\endlastfoot
	\cite{Sahiner1996} & Detect masses & \texttt{INPUT -> CONV -> SIGMOID -> FC -> SIGMOID} & $16\times 16 \times 3$ \newline $7 \times 7 \times 3$ \newline $1\times 1 \times 1$ & $10 \times 10$ \newline $7 \times 7$ & 1047\\
	\cite{Lo1995}& Detect individual microcalcifications& \texttt{INPUT -> [CONV -> SIGMOID]*2 -> FC -> SIGMOID} & $16\times 16 \times 1$ \newline $12 \times 12 \times 12$\newline $8\times 8 \times 12$\newline $1 \times 1 \times 2$ & $5 \times 5$\newline $5 \times 5$ \newline $8 \times 8$& 5436 \\
	\cite{Lo1998}& Detect individual microcalcifications & \texttt{INPUT -> GAUSSIAN -> [CONV -> SIGMOID]*2 -> FC -> SIGMOID} & $16\times 16 \times 1$ \newline $12 \times 12 \times 10$\newline $8\times 8 \times 10$\newline $1 \times 1 \times 2$ & $5 \times 5$\newline $5 \times 5$ \newline $8 \times 8$& 4530 \\
	\cite{Gurcan2002}& Detect individual microcalcifications & \texttt{INPUT -> [CONV -> SIGMOID]*2 -> FC -> SIGMOID} & $16\times 16 \times 1$ \newline $12 \times 12 \times 14$\newline $6\times 6 \times 10$\newline $1 \times 1 \times 1$ & $5 \times 5$\newline $7 \times 7$ \newline $6 \times 6$& 7570 \\
	\cite{Ge2006}& Detect individual microcalcifications & \texttt{INPUT -> [CONV -> SIGMOID]*2 -> FC -> SIGMOID} & $16\times 16 \times 1$ \newline $12 \times 12 \times 14$\newline $6\times 6 \times 10$\newline $1 \times 1 \times 1$ & $5 \times 5$\newline $7 \times 7$ \newline $6 \times 6$& 7570 \\
%		\cite{Agarwal2015}& Diagnose lesions & \texttt{INPUT -> [CONV -> RELU]*2 -> POOL -> [CONV -> RELU -> POOL]*3 -> [FC -> RELU]*3 -> SOFTMAX} & $64\times 64 \times 1$ \newline $64 \times 64 \times 32$\newline $32\times 32 \times 64$\newline $16 \times 16 \times 128$ \newline $8 \times 8 \times 256$ \newline $4 \times 4 \times 512$ \newline $1 \times 1 \times 256$ \newline $1 \times 1 \times 64$ \newline $1 \times 1 \times 2$ & $3 \times 3$ \newline $3 \times 3$ \newline $3 \times 3$ \newline $3 \times 3$ \newline $3 \times 3$ \newline $4 \times 4$ \newline $1 \times 1$ \newline $1 \times 1$ & 3.68M \\
	\cite{Arevalo2016}& Diagnose masses & \texttt{INPUT -> [CONV -> RELU -> POOL]*2 -> MAXOUT -> SOFTMAX} & $150\times 150 \times 1$ \newline $140 \times 140 \times 64$\newline $35\times 35 \times 64$\newline $32 \times 32 \times 64$ \newline $8 \times 8 \times 64$ \newline $1 \times 1 \times 400$ \newline $1 \times 1 \times 2$ & $11 \times 11$ \newline $5 \times 5$ \newline $4 \times 4$ \newline $4 \times 4$ \newline $8 \times 8$ \newline $1 \times 1$ & 3.35M \\
	\cite{Dubrovina2015}& Segment tissue & \texttt{INPUT -> [CONV -> RELU -> POOL]*3 -> [FC -> RELU]*2 -> SOFTMAX} & $61\times 61 \times 1$ \newline $55 \times 55 \times 16$\newline $27\times 27 \times 16$\newline $23 \times 23 \times 16$ \newline $11 \times 11 \times 16$ \newline $6 \times 6 \times 16$ \newline $3 \times 3 \times 16$ \newline $1 \times 1 \times 128$ \newline $1 \times 1 \times 16$ \newline $1 \times 1 \times 4$ & $7 \times 7$ \newline $3 \times 3$ \newline $5 \times 5$ \newline $3 \times 3$ \newline $5 \times 5$ \newline $3 \times 3$ \newline $3 \times 3$ \newline $1 \times 1$ \newline $1 \times 1$ & 34324 \\
\end{longtable}
\end{landscape}


\begin{comment} 
Groups working on convnets for breast cancer:
Georgetown University Medical Center: Shih-Chung Lo, Matthew Freedman, Huai Li
Michigan Medical Center: Heang-Ping Chan, Sahiner, Hadjiiski, Helvie, Gurcan, Wei j and Ge, J
University of chicago (MTANN): Suzuki Kenji (not quite convnets)

Other deep learning applications:
Cruz-Roa mitosis detection in breast cancer histology images,
Ciresan similar

CAD review:
Tang2009
2013 breast cancer diagnosis a review or other good review.
Work at Tec.
\end{comment}


%************************* Petrick2013 *****************************************
% Petrick, N., Sahiner, B., Armato III, S.G., Bert, A., Correale, L., Delsanto, S., Freedman, M.T., Fryd, D., Gur, D., Hadjiiski, L., Huo, Z., Jiang, Y., Morra, L., Paquerault, S., Raykar, V., Samuelson, F., Summers, R.M., Tourassi, G., Yoshida, H., Zheng, B., Zhou, C., Chan, H.-P. Evaluation of computer-aided detection and diagnosis systems (2013) Medical Physics, 40 (8), art. no. 087001, .
% on how should CAd systems be evaluated. Nop.
